<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>模型配置方案 on FastGPT</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/</link><description>Recent content in 模型配置方案 on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="https://doc.tryfastgpt.ai/docs/development/modelconfig/index.xml" rel="self" type="application/rss+xml"/><item><title>通过 OneAPI 接入模型</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/one-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/one-api/</guid><description>FastGPT 目前采用模型分离的部署方案，FastGPT 中只兼容 OpenAI 的模型规范（OpenAI 不存在的模型采用一个较为通用的规范），并通过 One API 来实现对不同模型接口的统一。
One API 是一个 OpenAI 接口管理 &amp;amp; 分发系统，可以通过标准的 OpenAI API 格式访问所有的大模型，开箱即用。
FastGPT 与 One API 关系 link可以把 One API 当做一个网关，FastGPT 与 One API 关系：
部署 linkDocker 版本 linkdocker-compose.yml 文件已加入了 OneAPI 配置，可直接使用。默认暴露在 3001 端口。
Sealos 版本 link 北京区: 点击部署 OneAPI 新加坡区(可用 GPT) 点击部署 OneAPI 部署完后，可以打开 OneAPI 访问链接，进行下一步操作。
OneAPI 基础教程 link概念 link 渠道： OneApi 中一个渠道对应一个 Api Key，这个 Api Key 可以是GPT、微软、ChatGLM、文心一言的。一个Api Key通常可以调用同一个厂商的多个模型。 One API 会根据请求传入的模型来决定使用哪一个渠道，如果一个模型对应了多个渠道，则会随机调用。 令牌：访问 One API 所需的凭证，只需要这1个凭证即可访问One API上配置的模型。因此FastGPT中，只需要配置One API的baseurl和令牌即可。令牌不要设置任何的模型范围权限，否则容易报错。 大致工作流程 link 客户端请求 One API 根据请求中的 model 参数，匹配对应的渠道（根据渠道里的模型进行匹配，必须完全一致）。如果匹配到多个渠道，则随机选择一个（同优先级）。 One API 向真正的地址发出请求。 One API 将结果返回给客户端。 1.</description></item><item><title>通过 SiliconCloud 体验开源模型</title><link>https://doc.tryfastgpt.ai/docs/development/modelconfig/siliconcloud/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://doc.tryfastgpt.ai/docs/development/modelconfig/siliconcloud/</guid><description>SiliconCloud(硅基流动) 是一个以提供开源模型调用为主的平台，并拥有自己的加速引擎。帮助用户低成本、快速的进行开源模型的测试和使用。实际体验下来，他们家模型的速度和稳定性都非常不错，并且种类丰富，覆盖语言、向量、重排、TTS、STT、绘图、视频生成模型，可以满足 FastGPT 中所有模型需求。
如果你想部分模型使用 SiliconCloud 的模型，可额外参考OneAPI接入硅基流动。
本文会介绍完全使用 SiliconCloud 模型来部署 FastGPT 的方案。
1. 注册 SiliconCloud 账号 link 点击注册硅基流动账号 进入控制台，获取 API key: https://cloud.siliconflow.cn/account/ak 2. 修改 FastGPT 环境变量 link OPENAI_BASE_URL=https://api.siliconflow.cn/v1 # 填写 SiliconCloud 控制台提供的 Api Key CHAT_API_KEY=sk-xxxxxx 3. 修改 FastGPT 配置文件 link我们选取 SiliconCloud 中的模型作为 FastGPT 配置。这里配置了 Qwen2.5 72b 的纯语言和视觉模型；选择 bge-m3 作为向量模型；选择 bge-reranker-v2-m3 作为重排模型。选择 fish-speech-1.5 作为语音模型；选择 SenseVoiceSmall 作为语音输入模型。
注意：ReRank 模型仍需配置一次 Api Key
{ &amp;#34;llmModels&amp;#34;: [ { &amp;#34;provider&amp;#34;: &amp;#34;Other&amp;#34;, // 模型提供商，主要用于分类展示，目前已经内置提供商包括：https://github.com/labring/FastGPT/blob/main/packages/global/core/ai/provider.ts, 可 pr 提供新的提供商，或直接填写 Other &amp;#34;model&amp;#34;: &amp;#34;Qwen/Qwen2.</description></item></channel></rss>